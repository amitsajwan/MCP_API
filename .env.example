# =============================
# Environment Configuration (.env example)
# Copy this file to .env and fill in only what you need.
# =============================

# --- LLM Summarization (Optional) ---
# Select provider: openai | huggingface | none (auto: openai if OPENAI_API_KEY set else none)
LLM_PROVIDER=huggingface
# OpenAI
OPENAI_API_KEY=
LLM_SUMMARY_MODEL=gpt-4o-mini
# Hugging Face Inference
HUGGINGFACE_MODEL=mistralai/Mistral-7B-Instruct-v0.2
HUGGINGFACE_API_TOKEN=

# Groq (OpenAI-compatible chat completions)
GROQ_MODEL=llama-3.1-8b-instant

# --- OpenAPI Specs Directory ---
# Path scanned for YAML/JSON OpenAPI specs.
OPENAPI_DIR=./openapi_specs

# --- Base URL Overrides ---
# Force ALL specs to use this base URL (e.g. local mock server)
# Example: FORCE_BASE_URL=http://localhost:9001
FORCE_BASE_URL=http://localhost:9001
# Per-spec override (spec name uppercased). Takes precedence over FORCE_BASE_URL.
FORCE_BASE_URL_CASH=

# --- Mock & Fallback Controls ---
# If set (any value), every spec base_url becomes MOCK_API_BASE_URL
MOCK_ALL=
# Base URL for mocks and auto-fallback (default below)
MOCK_API_BASE_URL=http://localhost:9001
# If set, failed calls to api.company.com auto-retry against MOCK_API_BASE_URL
AUTO_MOCK_FALLBACK=

# --- Login (optional) ---
# Custom login endpoint if not <base_url>/login
LOGIN_URL=

# --- Logging ---
LOG_LEVEL=INFO

# --- Quick Recipes ---
# 1) Pure mock, no LLM:          FORCE_BASE_URL=http://localhost:9001  (leave LLM_PROVIDER empty)
# 2) Auto fallback to mock:      AUTO_MOCK_FALLBACK=1
# 3) Force all specs to mock:    MOCK_ALL=1
# 4) OpenAI summaries:           OPENAI_API_KEY=sk-...  (optionally LLM_PROVIDER=openai)
# 5) Hugging Face summaries:     LLM_PROVIDER=huggingface HUGGINGFACE_MODEL=mistralai/Mistral-7B-Instruct-v0.2
# 6) Groq summaries:             LLM_PROVIDER=groq GROQ_API_KEY=... (optional GROQ_MODEL=llama-3.1-8b-instant)
# 7) Disable LLM entirely:       LLM_PROVIDER=none
# =============================
