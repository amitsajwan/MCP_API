# MCP System Test Suite

This directory contains comprehensive test cases for the MCP (Model Context Protocol) system.

## ğŸ§ª Test Structure

### **Unit Tests**
- `test_mcp_server.py` - Tests MCP server functionality
- `test_mcp_client.py` - Tests MCP client and Azure integration
- `test_mcp_service.py` - Tests MCP service orchestration
- `test_web_ui.py` - Tests web UI functionality

### **Integration Tests**
- `test_integration.py` - Tests complete system integration

### **Test Runner**
- `test_runner.py` - Runs all tests with comprehensive reporting

## ğŸš€ Running Tests

### **Run All Tests**
```bash
cd /workspace/tests
python test_runner.py
```

### **Run Quick Tests (Unit Tests Only)**
```bash
python test_runner.py quick
```

### **Run Integration Tests Only**
```bash
python test_runner.py integration
```

### **Run Specific Tests**
```bash
python test_runner.py specific test_mcp_server test_mcp_client
```

### **Run Individual Test Files**
```bash
python test_mcp_server.py
python test_mcp_client.py
python test_mcp_service.py
python test_web_ui.py
python test_integration.py
```

## ğŸ“‹ Test Coverage

### **MCP Server Tests**
- âœ… Server initialization
- âœ… Tool registration
- âœ… API specification loading
- âœ… Tool execution
- âœ… Authentication handling
- âœ… Error handling

### **MCP Client Tests**
- âœ… Azure client creation
- âœ… Tool discovery and preparation
- âœ… Tool execution
- âœ… Response handling
- âœ… Error handling
- âœ… Environment variable handling

### **MCP Service Tests**
- âœ… Service initialization
- âœ… Message processing
- âœ… Tool execution orchestration
- âœ… Capability analysis
- âœ… Error handling
- âœ… Conversation management

### **Web UI Tests**
- âœ… Flask app initialization
- âœ… SocketIO event handling
- âœ… MCP service integration
- âœ… Message processing
- âœ… Error handling
- âœ… Conversation flow

### **Integration Tests**
- âœ… End-to-end message processing
- âœ… Tool execution flow
- âœ… Error propagation
- âœ… Performance testing
- âœ… Reliability testing

## ğŸ”§ Test Configuration

### **Environment Variables**
Tests use mocked environment variables to avoid requiring actual Azure credentials:
```python
AZURE_OPENAI_ENDPOINT=https://test.openai.azure.com/
AZURE_DEPLOYMENT_NAME=gpt-4o
AZURE_CLIENT_ID=test-client-id
AZURE_CLIENT_SECRET=test-secret
AZURE_TENANT_ID=test-tenant
```

### **Mocking Strategy**
- **Azure OpenAI**: Mocked to avoid API calls
- **MCP Server**: Mocked for unit tests, real for integration
- **Network Requests**: Mocked to avoid external dependencies
- **File System**: Uses temporary directories

## ğŸ“Š Test Results

### **Expected Results**
- **Unit Tests**: Should all pass with mocks
- **Integration Tests**: May have some failures without real Azure setup
- **Performance Tests**: Should complete within reasonable time

### **Test Output**
```
ğŸ§ª MCP System Test Suite
==================================================

ğŸ” Running test_mcp_server...
------------------------------
âœ… test_mcp_server completed: 8 tests

ğŸ” Running test_mcp_client...
------------------------------
âœ… test_mcp_client completed: 12 tests

ğŸ“Š Test Summary
==================================================
Total Tests: 45
Passed: 42
Failed: 2
Errors: 1
Skipped: 0
Duration: 3.45 seconds

ğŸ‰ All tests passed!
```

## ğŸ› Troubleshooting

### **Common Issues**

1. **Import Errors**
   - Ensure you're running from the tests directory
   - Check that parent directory is in Python path

2. **Mock Failures**
   - Some tests may fail if mocks are not properly configured
   - Check mock setup in test methods

3. **Environment Issues**
   - Tests use mocked environment variables
   - Real Azure credentials not required for most tests

### **Debug Mode**
Run individual test files with verbose output:
```bash
python -m unittest test_mcp_server -v
```

## ğŸ”„ Continuous Integration

### **Pre-commit Hooks**
```bash
# Run tests before committing
python test_runner.py quick
```

### **CI Pipeline**
```yaml
# Example GitHub Actions workflow
- name: Run Tests
  run: |
    cd tests
    python test_runner.py
```

## ğŸ“ˆ Test Metrics

### **Coverage Goals**
- **Unit Tests**: 90%+ code coverage
- **Integration Tests**: 80%+ flow coverage
- **Error Handling**: 100% error path coverage

### **Performance Goals**
- **Initialization**: < 5 seconds
- **Message Processing**: < 2 seconds
- **Memory Usage**: < 100MB per test

## ğŸ¯ Test Philosophy

### **Testing Principles**
1. **Isolation**: Each test is independent
2. **Mocking**: External dependencies are mocked
3. **Coverage**: All code paths are tested
4. **Reliability**: Tests are deterministic
5. **Performance**: Tests run quickly

### **Test Categories**
1. **Unit Tests**: Test individual components
2. **Integration Tests**: Test component interactions
3. **Performance Tests**: Test system performance
4. **Reliability Tests**: Test error handling and recovery

This test suite ensures the MCP system is robust, reliable, and ready for production use! ğŸš€